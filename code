import pandas as pd
import numpy as np
from datetime import datetime
import dateutil.parser
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error
import warnings
warnings.filterwarnings('ignore')

def load_data(file_path):
    """Load CSV data into a pandas DataFrame"""
    return pd.read_csv(file_path)

def extract_features(df):
    """Comprehensive feature engineering"""
    df = df.copy()
    
    # Handle missing values
    df['year'] = pd.to_numeric(df['year'], errors='coerce')
    df['odometer'] = pd.to_numeric(df['odometer'], errors='coerce')
    
    # Parse posting date with proper error handling
    try:
        df['posting_date'] = pd.to_datetime(df['posting_date'], errors='coerce')
        # Check if we have valid datetime values
        if df['posting_date'].dtype == 'datetime64[ns]':
            df['posting_year'] = df['posting_date'].dt.year
            df['posting_month'] = df['posting_date'].dt.month
        else:
            # If conversion failed, create default values
            print("Warning: posting_date conversion failed, using defaults")
            df['posting_year'] = 2021  # Default year
            df['posting_month'] = 6    # Default month
    except Exception as e:
        print(f"Error processing posting_date: {e}")
        # Fallback: create default values
        df['posting_year'] = 2021
        df['posting_month'] = 6
    
    # Handle any remaining NaN values in posting_year and posting_month
    df['posting_year'] = df['posting_year'].fillna(2021)
    df['posting_month'] = df['posting_month'].fillna(6)
    
    # Age feature (most important)
    df['age'] = df['posting_year'] - df['year']
    
    # Handle outliers and missing values
    df['age'] = df['age'].fillna(df['age'].median())
    df['age'] = np.clip(df['age'], 0, 50)  # Cap age at 50 years
    
    df['odometer'] = df['odometer'].fillna(df['odometer'].median())
    df['odometer'] = np.clip(df['odometer'], 0, 500000)  # Cap odometer
    
    # Odometer per year (mileage intensity)
    df['odometer_per_year'] = np.where(df['age'] > 0, df['odometer'] / df['age'], df['odometer'])
    df['odometer_per_year'] = np.clip(df['odometer_per_year'], 0, 50000)
    
    # Log transformations for skewed features
    df['log_odometer'] = np.log1p(df['odometer'])
    df['age_squared'] = df['age'] ** 2
    
    # Brand value categories (based on typical luxury/economy classification)
    luxury_brands = ['bmw', 'mercedes-benz', 'audi', 'lexus', 'infiniti', 'cadillac', 'lincoln', 'acura']
    premium_brands = ['toyota', 'honda', 'subaru', 'mazda', 'volkswagen', 'volvo']
    
    df['manufacturer'] = df['manufacturer'].fillna('unknown').str.lower()
    df['brand_luxury'] = df['manufacturer'].isin(luxury_brands).astype(int)
    df['brand_premium'] = df['manufacturer'].isin(premium_brands).astype(int)
    
    # Condition ordinal encoding
    condition_order = ['salvage', 'fair', 'good', 'excellent', 'like new', 'new']
    df['condition'] = df['condition'].fillna('good')
    df['condition_score'] = df['condition'].map({c: i for i, c in enumerate(condition_order)})
    df['condition_score'] = df['condition_score'].fillna(2)  # Default to 'good'
    
    # Title status (clean is most valuable)
    df['title_clean'] = (df['title_status'] == 'clean').astype(int)
    
    # Fuel type
    df['fuel_gas'] = (df['fuel'] == 'gas').astype(int)
    df['fuel_hybrid'] = (df['fuel'] == 'hybrid').astype(int)
    df['fuel_electric'] = (df['fuel'] == 'electric').astype(int)
    
    # Transmission
    df['transmission_auto'] = (df['transmission'] == 'automatic').astype(int)
    
    # Drive type
    df['drive_4wd'] = (df['drive'] == '4wd').astype(int)
    df['drive_fwd'] = (df['drive'] == 'fwd').astype(int)
    df['drive_rwd'] = (df['drive'] == 'rwd').astype(int)
    
    # Size categories
    df['size_full'] = (df['size'] == 'full-size').astype(int)
    df['size_mid'] = (df['size'] == 'mid-size').astype(int)
    df['size_compact'] = (df['size'] == 'compact').astype(int)
    
    # Type categories
    df['type_suv'] = (df['type'] == 'SUV').astype(int)
    df['type_sedan'] = (df['type'] == 'sedan').astype(int)
    df['type_truck'] = (df['type'] == 'truck').astype(int)
    df['type_coupe'] = (df['type'] == 'coupe').astype(int)
    
    # Cylinders processing
    df['cylinders'] = df['cylinders'].fillna('6 cylinders')
    df['cylinder_count'] = df['cylinders'].str.extract('(\d+)').astype(float)
    df['cylinder_count'] = df['cylinder_count'].fillna(6)
    
    # Seasonal effects
    df['posting_month_sin'] = np.sin(2 * np.pi * df['posting_month'] / 12)
    df['posting_month_cos'] = np.cos(2 * np.pi * df['posting_month'] / 12)
    
    # Feature interactions
    df['age_odometer_interaction'] = df['age'] * df['log_odometer']
    df['luxury_age_interaction'] = df['brand_luxury'] * df['age']
    df['condition_age_interaction'] = df['condition_score'] * df['age']
    
    return df

def select_features(df):
    """Select the most important features for modeling"""
    feature_columns = [
        # Core features
        'age', 'age_squared', 'odometer', 'log_odometer', 'odometer_per_year',
        
        # Brand features
        'brand_luxury', 'brand_premium',
        
        # Condition and status
        'condition_score', 'title_clean',
        
        # Technical specs
        'cylinder_count', 'fuel_gas', 'fuel_hybrid', 'fuel_electric',
        'transmission_auto', 'drive_4wd', 'drive_fwd', 'drive_rwd',
        
        # Size and type
        'size_full', 'size_mid', 'size_compact',
        'type_suv', 'type_sedan', 'type_truck', 'type_coupe',
        
        # Seasonal
        'posting_month_sin', 'posting_month_cos',
        
        # Interactions
        'age_odometer_interaction', 'luxury_age_interaction', 'condition_age_interaction'
    ]
    
    return df[feature_columns]

def remove_outliers(df, target_col='price', threshold=3):
    """Remove price outliers using IQR method"""
    if target_col in df.columns:
        Q1 = df[target_col].quantile(0.25)
        Q3 = df[target_col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # Keep reasonable price range
        df = df[(df[target_col] >= max(500, lower_bound)) & (df[target_col] <= min(100000, upper_bound))]
    
    return df

def main():
    print("Loading data...")
    
    # Load training and test data
    train_df = load_data('/content/drive/MyDrive/cse520/used_cars_train.csv')  # Updated for CSV files
    test_df = load_data('/content/drive/MyDrive/cse520/used_cars_test.csv')    # Updated for CSV files
    
    print(f"Training data shape: {train_df.shape}")
    print(f"Test data shape: {test_df.shape}")
    
    # Check data types and first few rows
    print("\nTraining data info:")
    print(train_df.dtypes)
    print("\nFirst few rows of posting_date:")
    print(train_df['posting_date'].head())
    
    # Feature engineering
    print("\nEngineering features...")
    train_df = extract_features(train_df)
    test_df = extract_features(test_df)
    
    # Remove outliers from training data
    train_df = remove_outliers(train_df, 'price')
    print(f"After outlier removal: {train_df.shape}")
    
    # Prepare features and target
    X_train = select_features(train_df)
    y_train = train_df['price'].values
    
    X_test = select_features(test_df)
    y_test = test_df['price'].values
    
    # Handle any remaining missing values
    X_train = X_train.fillna(0)
    X_test = X_test.fillna(0)
    
    print(f"Number of features: {X_train.shape[1]}")
    
    # Feature scaling
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Try multiple models
    models = {
        'Linear Regression': LinearRegression(),
        'Ridge (alpha=100)': Ridge(alpha=100),
        'Ridge (alpha=500)': Ridge(alpha=500),
        'Ridge (alpha=1000)': Ridge(alpha=1000),
        'Lasso (alpha=100)': Lasso(alpha=100),
        'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42),
        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=6, random_state=42)
    }
    
    best_mse = float('inf')
    best_model = None
    best_model_name = None
    
    print("\nTesting models...")
    for name, model in models.items():
        # Fit model
        model.fit(X_train_scaled, y_train)
        
        # Predict on test set
        y_pred = model.predict(X_test_scaled)
        
        # Calculate MSE
        mse = mean_squared_error(y_test, y_pred)
        
        print(f"{name}: MSE = {mse:,.0f}")
        
        if mse < best_mse:
            best_mse = mse
            best_model = model
            best_model_name = name
    
    print(f"\nBest model: {best_model_name}")
    print(f"Best MSE: {best_mse:,.0f}")
    
    # Baseline comparison
    baselines = [180000000, 160000000, 120000000]
    beaten_baselines = sum(1 for b in baselines if best_mse < b)
    
    print(f"\nBaseline comparison:")
    for i, baseline in enumerate(baselines, 1):
        status = "✓ BEATEN" if best_mse < baseline else "✗ Not beaten"
        print(f"Baseline {i} ({baseline:,}): {status}")
    
    print(f"\nTotal baselines beaten: {beaten_baselines}/3")
    
    # Ensemble approach for even better results
    if beaten_baselines < 3:
        print("\nTrying ensemble approach...")
        
        # Create ensemble of top models
        ridge_model = Ridge(alpha=500)
        rf_model = RandomForestRegressor(n_estimators=150, max_depth=12, random_state=42)
        gb_model = GradientBoostingRegressor(n_estimators=150, max_depth=5, random_state=42)
        
        # Fit all models
        ridge_model.fit(X_train_scaled, y_train)
        rf_model.fit(X_train_scaled, y_train)
        gb_model.fit(X_train_scaled, y_train)
        
        # Ensemble predictions (weighted average)
        pred_ridge = ridge_model.predict(X_test_scaled)
        pred_rf = rf_model.predict(X_test_scaled)
        pred_gb = gb_model.predict(X_test_scaled)
        
        # Weighted ensemble
        ensemble_pred = 0.3 * pred_ridge + 0.4 * pred_rf + 0.3 * pred_gb
        ensemble_mse = mean_squared_error(y_test, ensemble_pred)
        
        print(f"Ensemble MSE: {ensemble_mse:,.0f}")
        
        if ensemble_mse < best_mse:
            best_mse = ensemble_mse
            print("Ensemble is the best model!")
            
            # Update baseline comparison
            beaten_baselines = sum(1 for b in baselines if best_mse < b)
            print(f"Ensemble baselines beaten: {beaten_baselines}/3")
    
    print(f"\nFinal MSE: {int(best_mse)}")
    return int(best_mse)

if __name__ == "__main__":
    final_mse = main()
